{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install gymnasium stable_baselines3[extra] box2d ipywidgets ffmpeg imageio --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Create environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Instantiate the agent\n",
    "model = PPO(\n",
    "    'MlpPolicy',\n",
    "    env,\n",
    "    verbose=1,\n",
    "    ##### YOUR HYPERPARAMETERS HERE!!!!\n",
    "    learning_rate=0.001,\n",
    "    batch_size=32,\n",
    "    )\n",
    "\n",
    "# Train the agent and display a progress bar\n",
    "model.learn(total_timesteps=int(100000), progress_bar=True)\n",
    "\n",
    "# Save the agent\n",
    "model.save(\"ppo_lunar\")\n",
    "#del model  # delete trained model to demonstrate loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class CustomProgressBarCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback that combines progress bar with training metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, total_timesteps):\n",
    "        super().__init__()\n",
    "        self.pbar = None\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.n_calls = 0\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        self.pbar = tqdm(total=self.total_timesteps)\n",
    "\n",
    "    def _on_step(self):\n",
    "        n_steps = self.locals.get('n_steps', 1)\n",
    "        self.pbar.update(n_steps)\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        self.pbar.close()\n",
    "        self.pbar = None\n",
    "\n",
    "# Create environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Instantiate the agent\n",
    "model = PPO(\n",
    "    'MlpPolicy',\n",
    "    env,\n",
    "    verbose=1,  # Keep verbose=1 to see the training metrics\n",
    "    learning_rate=0.001,\n",
    "    batch_size=32,\n",
    "    tensorboard_log=\"./lunar_lander_tensorboard/\"\n",
    ")\n",
    "\n",
    "# Total timesteps for training\n",
    "total_timesteps = 10000\n",
    "\n",
    "# Create and use the custom callback\n",
    "callback = CustomProgressBarCallback(total_timesteps)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(\n",
    "    total_timesteps=total_timesteps,\n",
    "    callback=callback,\n",
    "    progress_bar=False  # Disable default progress bar to use our custom one\n",
    ")\n",
    "\n",
    "# Save the agent\n",
    "model.save(\"ppo_lunar\")\n",
    "\n",
    "# Evaluate the trained agent\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "print('\\nFinal Evaluation:')\n",
    "print(f'Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create images directory if it doesn't exist\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.makedirs(\"images\")\n",
    "\n",
    "# Load the trained agent\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "model = PPO.load(\"ppo_lunar\", env=env)\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "print('Mean reward:', mean_reward, 'Std. reward:', std_reward)\n",
    "\n",
    "# Test the trained agent and save visualization\n",
    "images = []\n",
    "episodes = 0\n",
    "obs, _ = env.reset()  # Updated reset call syntax\n",
    "\n",
    "while episodes < 5:  # Limit to 5 episodes for reasonable file sizes\n",
    "    img = env.render()\n",
    "    images.append(img)\n",
    "    \n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)  # Updated step call syntax\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        episodes += 1\n",
    "        print(f'Episode {episodes} finished with reward {reward}')\n",
    "        \n",
    "        # Save episode as GIF\n",
    "        if len(images) > 0:\n",
    "            print(f'Saving episode {episodes} animation...')\n",
    "            imageio.mimsave(\n",
    "                f'images/lunar_lander_episode_{episodes}.gif',\n",
    "                images,\n",
    "                fps=30\n",
    "            )\n",
    "        \n",
    "        # Reset for next episode\n",
    "        images = []\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "env.close()\n",
    "print(\"Done! Check the 'images' directory for the animation files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
